{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping Kottayam. Already scraped.\n",
      "Scraping completed.\n"
     ]
    }
   ],
   "source": [
    "#datacollection and cleaning\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as Soup\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "locations = [\"Delhi\", \"Mumbai\", \"Kolkata\", \"Chennai\"]\n",
    "# Function to scrape data from Booking.com\n",
    "def scrape_bookingdotcom(destination, checkin_date, checkout_date):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36'\n",
    "    }\n",
    "    req = requests.get(\n",
    "        f\"https://www.booking.com/searchresults.en-gb.html?ss={destination}&checkin={checkin_date}&checkout={checkout_date}&offset==0\",\n",
    "        headers=headers).text\n",
    "    soup = Soup(req, 'html.parser')\n",
    "    ap = soup.find(\"ol\", {\"class\": \"a8b500abde\"}).text\n",
    "\n",
    "    df = pd.DataFrame(columns=[\"price\", \"location\", \"distance\", \"amenities\", \"ratings\", \"type\"])\n",
    "    for pages in range(0, int(ap[len(ap) - 1])):\n",
    "        req = requests.get(\n",
    "            f\"https://www.booking.com/searchresults.en-gb.html?ss={destination}&checkin={checkin_date}&checkout={checkout_date}&offset=={pages * 25}\",\n",
    "            headers=headers).text\n",
    "        soup = Soup(req, 'html.parser')\n",
    "        apts = soup.find_all(\"div\", {\"class\": \"d20f4628d0\"})\n",
    "        rows = []\n",
    "\n",
    "        for a in range(0, len(apts)):\n",
    "            obj = {}\n",
    "\n",
    "            try:\n",
    "                obj[\"price\"] = apts[a].find(\"span\", {\"class\": \"fcab3ed991 fbd1d3018c e729ed5ab6\"}).text\n",
    "            except:\n",
    "                obj[\"price\"] = None\n",
    "\n",
    "            try:\n",
    "                obj[\"distance\"] = apts[a].find(\"span\", {\"class\": \"cb5ebe3ffb\"}).text\n",
    "            except:\n",
    "                obj[\"distance\"] = None\n",
    "\n",
    "            try:\n",
    "                ap1 = apts[a].find('a', href=True)\n",
    "                link = ap1['href']\n",
    "                req1 = requests.get(link, headers=headers).text\n",
    "                soup2 = Soup(req1, 'html.parser')\n",
    "                obj[\"amenities\"] = soup2.find(\"div\", {\"class\": \"e5e0727360\"}).text\n",
    "            except:\n",
    "                obj[\"amenities\"] = None\n",
    "\n",
    "            try:\n",
    "                obj[\"ratings\"] = apts[a].find(\"div\", {\"class\": \"b5cd09854e d10a6220b4\"}).text\n",
    "            except:\n",
    "                obj[\"ratings\"] = None\n",
    "\n",
    "            try:\n",
    "                obj[\"type\"] = apts[a].find(\"span\", {\"class\": \"df597226dd\"}).text\n",
    "            except:\n",
    "                obj[\"type\"] = None\n",
    "\n",
    "            try:\n",
    "                obj[\"location\"] = apts[a].find(\"span\", {\"class\": \"f4bd0794db b4273d69aa\"}).text\n",
    "            except:\n",
    "                obj[\"location\"] = None\n",
    "\n",
    "            rows.append(obj)\n",
    "\n",
    "        df = pd.concat([df, pd.DataFrame(rows)])\n",
    "\n",
    "    # Data cleaning\n",
    "    df[\"price\"] = df[\"price\"].str.replace(r\"â‚¹\", \"\")\n",
    "    df[\"price\"] = df[\"price\"].str.replace(r\" \", \"\")\n",
    "    df[\"price\"] = df[\"price\"].str.replace(r\",\", \"\")\n",
    "    df[\"price\"] = df[\"price\"].str.strip()\n",
    "    df['price'] = pd.to_numeric(df['price'])\n",
    "    df['ratings'] = pd.to_numeric(df['ratings'], errors='coerce')\n",
    "    df['ratings'] = df['ratings'].fillna(df['ratings'].mean())\n",
    "\n",
    "    return df\n",
    "\n",
    "# Load scraped locations from JSON file\n",
    "scraped_locations_file = \"scraped_locations.json\"  # JSON file to store scraped locations\n",
    "try:\n",
    "    with open(scraped_locations_file, \"r\") as file:\n",
    "        scraped_locations = set(json.load(file))\n",
    "except FileNotFoundError:\n",
    "    scraped_locations = set()\n",
    "\n",
    "# Take user input for the location, check-in date, and check-out date\n",
    "user_location = input(\"Enter a location: \").strip().capitalize()\n",
    "current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "checkin_date = current_date\n",
    "checkout_date = (datetime.now() + timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Check if location has already been scraped\n",
    "if user_location.lower() in map(str.lower, scraped_locations):\n",
    "    print(f\"Skipping {user_location}. Already scraped.\")\n",
    "else:\n",
    "    # Scrape data for the location\n",
    "    df = scrape_bookingdotcom(user_location, checkin_date, checkout_date)\n",
    "\n",
    "    # Update the set of scraped locations\n",
    "    scraped_locations.add(user_location)\n",
    "\n",
    "    # Save the data to a CSV file with current date in the filename\n",
    "    csv_filename = f\"{user_location}_{current_date}.csv\"\n",
    "    df.to_csv(csv_filename, index=False)\n",
    "\n",
    "    print(f\"Scraped and saved data for {user_location}.\")\n",
    "for location in locations:\n",
    "    if location.lower() not in map(str.lower, scraped_locations):\n",
    "        # Scrape data for the location\n",
    "        df = scrape_bookingdotcom(location, checkin_date, checkout_date)\n",
    "\n",
    "        # Update the set of scraped locations\n",
    "        scraped_locations.add(location)\n",
    "\n",
    "        # Save the data to a CSV file with current date in the filename\n",
    "        csv_filename = f\"{location}_{current_date}.csv\"\n",
    "        df.to_csv(csv_filename, index=False)\n",
    "\n",
    "        print(f\"Scraped and saved data for {location}.\")\n",
    "\n",
    "# Save the updated set of scraped locations to the JSON file\n",
    "with open(scraped_locations_file, \"w\") as file:\n",
    "    json.dump(list(scraped_locations), file)\n",
    "\n",
    "# Combine all CSV files into a single dataframe\n",
    "combined_df = pd.DataFrame()\n",
    "for location in list(scraped_locations):\n",
    "    csv_filename = f\"{location}_{current_date}.csv\"\n",
    "    if os.path.isfile(csv_filename):\n",
    "        df = pd.read_csv(csv_filename)\n",
    "        combined_df = pd.concat([combined_df, df])\n",
    "\n",
    "# Save the combined dataframe to a CSV file with current date in the filename\n",
    "final_csv_filename = f\"combined_{current_date}.csv\"\n",
    "combined_df.to_csv(final_csv_filename, index=False)\n",
    "\n",
    "print(\"Scraping completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     price  location   ratings  type\n",
      "0     1512        10  5.200000    15\n",
      "1     4500        10  7.900000    54\n",
      "2     2700        10  6.400000     7\n",
      "3     2650        10  8.400000    44\n",
      "4     2765        10  7.800000     8\n",
      "..     ...       ...       ...   ...\n",
      "494   3150         9  8.500000     7\n",
      "495   1606         9  5.500000     7\n",
      "496   1532         9  5.000000    44\n",
      "497   3040        15  7.834783    44\n",
      "498   3325         9  7.500000    50\n",
      "\n",
      "[499 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\jaida\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jaida\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "import re\n",
    "import joblib\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download the necessary NLTK modules\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Read the data into a Pandas DataFrame\n",
    "df = pd.read_csv(final_csv_filename)\n",
    "\n",
    "# Fill in any missing values in the amenities column with an empty string\n",
    "df['amenities'].fillna('', inplace=True)\n",
    "\n",
    "# Define a custom tokenizer that removes adverbs, adjectives, and verbs\n",
    "\n",
    "\n",
    "def custom_tokenizer(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    pos_tags = pos_tag(tokens)  # Perform POS tagging\n",
    "    filtered_tokens = [token for token, pos in pos_tags if pos not in [\n",
    "        'RB', 'JJ', 'VB']]  # Filter out adverbs, adjectives, and verbs\n",
    "    return filtered_tokens\n",
    "\n",
    "\n",
    "# Create a TfidfVectorizer object and fit it to the amenities column\n",
    "vectorizer = TfidfVectorizer(tokenizer=custom_tokenizer, ngram_range=(\n",
    "    1, 2), stop_words=set(stopwords.words('english')))\n",
    "#amenities_tfidf = vectorizer.fit_transform(df['amenities'])\n",
    "\n",
    "# Convert the TfidfVectorizer output to a DataFrame\n",
    "amenities_df = pd.DataFrame()  \n",
    "#amenities_tfidf.toarray(), columns=vectorizer.get_feature_names())\n",
    "\n",
    "# Create a LabelEncoder object and fit it to the type and location columns\n",
    "label_encoder = LabelEncoder()\n",
    "df['type'] = label_encoder.fit_transform(df['type'].str.lower())\n",
    "df['location'] = label_encoder.fit_transform(df['location'].str.lower())\n",
    "\n",
    "# Save the LabelEncoder objects to disk\n",
    "joblib.dump(label_encoder, 'label_encoder.joblib')\n",
    "\n",
    "# Drop the amenities and distance columns from the DataFrame\n",
    "df_processed = df.drop(columns=['amenities', 'distance'])\n",
    "\n",
    "# Rename the columns in the DataFrame\n",
    "df_processed.columns = [re.sub('[^A-Za-z]+', '', col)\n",
    "                        for col in df_processed.columns]\n",
    "\n",
    "# Write the processed DataFrame to a CSV file\n",
    "df_processed.to_csv('preprocessed.csv', index=False)\n",
    "\n",
    "# Print the processed DataFrame\n",
    "print(df_processed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "df = pd.read_csv('preprocessed.csv')\n",
    "df=df.drop('ratings',axis=1)\n",
    "X = df.drop('price', axis=1)  # Adjust the column name for your target variable\n",
    "y = df['price']\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=2)  # Set the number of components you want to retain\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Create a new DataFrame with the reduced dimensions\n",
    "df_pca = pd.DataFrame(data=X_pca, columns=['PC1', 'PC2'])\n",
    "\n",
    "# Concatenate the reduced dimensions with the target variable\n",
    "df_pca_target = pd.concat([df_pca, y], axis=1)\n",
    "\n",
    "# Save the PCA-reduced dataset to a new CSV file\n",
    "df_pca_target.to_csv('pca_reduced.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c51ff_row8_col1, #T_c51ff_row12_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c51ff\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c51ff_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_c51ff_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c51ff_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_c51ff_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_c51ff_row0_col1\" class=\"data row0 col1\" >123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c51ff_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_c51ff_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_c51ff_row1_col1\" class=\"data row1 col1\" >price</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c51ff_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_c51ff_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_c51ff_row2_col1\" class=\"data row2 col1\" >Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c51ff_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_c51ff_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
       "      <td id=\"T_c51ff_row3_col1\" class=\"data row3 col1\" >(499, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c51ff_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_c51ff_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_c51ff_row4_col1\" class=\"data row4 col1\" >(499, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c51ff_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_c51ff_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_c51ff_row5_col1\" class=\"data row5 col1\" >(399, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c51ff_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_c51ff_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_c51ff_row6_col1\" class=\"data row6 col1\" >(100, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c51ff_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_c51ff_row7_col0\" class=\"data row7 col0\" >Numeric features</td>\n",
       "      <td id=\"T_c51ff_row7_col1\" class=\"data row7 col1\" >2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c51ff_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_c51ff_row8_col0\" class=\"data row8 col0\" >Preprocess</td>\n",
       "      <td id=\"T_c51ff_row8_col1\" class=\"data row8 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c51ff_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_c51ff_row9_col0\" class=\"data row9 col0\" >Imputation type</td>\n",
       "      <td id=\"T_c51ff_row9_col1\" class=\"data row9 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c51ff_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_c51ff_row10_col0\" class=\"data row10 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_c51ff_row10_col1\" class=\"data row10 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c51ff_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_c51ff_row11_col0\" class=\"data row11 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_c51ff_row11_col1\" class=\"data row11 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c51ff_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_c51ff_row12_col0\" class=\"data row12 col0\" >Normalize</td>\n",
       "      <td id=\"T_c51ff_row12_col1\" class=\"data row12 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c51ff_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_c51ff_row13_col0\" class=\"data row13 col0\" >Normalize method</td>\n",
       "      <td id=\"T_c51ff_row13_col1\" class=\"data row13 col1\" >zscore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c51ff_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_c51ff_row14_col0\" class=\"data row14 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_c51ff_row14_col1\" class=\"data row14 col1\" >KFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c51ff_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_c51ff_row15_col0\" class=\"data row15 col0\" >Fold Number</td>\n",
       "      <td id=\"T_c51ff_row15_col1\" class=\"data row15 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c51ff_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_c51ff_row16_col0\" class=\"data row16 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_c51ff_row16_col1\" class=\"data row16 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c51ff_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_c51ff_row17_col0\" class=\"data row17 col0\" >Use GPU</td>\n",
       "      <td id=\"T_c51ff_row17_col1\" class=\"data row17 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c51ff_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_c51ff_row18_col0\" class=\"data row18 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_c51ff_row18_col1\" class=\"data row18 col1\" >MlflowLogger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c51ff_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_c51ff_row19_col0\" class=\"data row19 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_c51ff_row19_col1\" class=\"data row19 col1\" >your_experiment_name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c51ff_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_c51ff_row20_col0\" class=\"data row20 col0\" >USI</td>\n",
       "      <td id=\"T_c51ff_row20_col1\" class=\"data row20 col1\" >fcb2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x181a7f98d00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_367ca th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_367ca_row0_col0, #T_367ca_row0_col6, #T_367ca_row1_col0, #T_367ca_row1_col1, #T_367ca_row1_col2, #T_367ca_row1_col3, #T_367ca_row1_col4, #T_367ca_row1_col5, #T_367ca_row2_col0, #T_367ca_row2_col1, #T_367ca_row2_col2, #T_367ca_row2_col3, #T_367ca_row2_col4, #T_367ca_row2_col5, #T_367ca_row2_col6, #T_367ca_row3_col0, #T_367ca_row3_col1, #T_367ca_row3_col2, #T_367ca_row3_col3, #T_367ca_row3_col4, #T_367ca_row3_col5, #T_367ca_row3_col6, #T_367ca_row4_col0, #T_367ca_row4_col1, #T_367ca_row4_col2, #T_367ca_row4_col3, #T_367ca_row4_col4, #T_367ca_row4_col5, #T_367ca_row4_col6, #T_367ca_row5_col0, #T_367ca_row5_col1, #T_367ca_row5_col2, #T_367ca_row5_col3, #T_367ca_row5_col4, #T_367ca_row5_col5, #T_367ca_row5_col6, #T_367ca_row6_col0, #T_367ca_row6_col1, #T_367ca_row6_col2, #T_367ca_row6_col3, #T_367ca_row6_col4, #T_367ca_row6_col5, #T_367ca_row6_col6, #T_367ca_row7_col0, #T_367ca_row7_col1, #T_367ca_row7_col2, #T_367ca_row7_col3, #T_367ca_row7_col4, #T_367ca_row7_col5, #T_367ca_row7_col6, #T_367ca_row8_col0, #T_367ca_row8_col1, #T_367ca_row8_col2, #T_367ca_row8_col3, #T_367ca_row8_col4, #T_367ca_row8_col5, #T_367ca_row8_col6, #T_367ca_row9_col0, #T_367ca_row9_col1, #T_367ca_row9_col2, #T_367ca_row9_col3, #T_367ca_row9_col4, #T_367ca_row9_col5, #T_367ca_row9_col6, #T_367ca_row10_col0, #T_367ca_row10_col1, #T_367ca_row10_col2, #T_367ca_row10_col3, #T_367ca_row10_col4, #T_367ca_row10_col5, #T_367ca_row10_col6, #T_367ca_row11_col0, #T_367ca_row11_col1, #T_367ca_row11_col2, #T_367ca_row11_col3, #T_367ca_row11_col4, #T_367ca_row11_col5, #T_367ca_row11_col6, #T_367ca_row12_col0, #T_367ca_row12_col1, #T_367ca_row12_col2, #T_367ca_row12_col3, #T_367ca_row12_col4, #T_367ca_row12_col5, #T_367ca_row12_col6, #T_367ca_row13_col0, #T_367ca_row13_col1, #T_367ca_row13_col2, #T_367ca_row13_col3, #T_367ca_row13_col4, #T_367ca_row13_col5, #T_367ca_row13_col6, #T_367ca_row14_col0, #T_367ca_row14_col1, #T_367ca_row14_col2, #T_367ca_row14_col3, #T_367ca_row14_col4, #T_367ca_row14_col5, #T_367ca_row14_col6, #T_367ca_row15_col0, #T_367ca_row15_col1, #T_367ca_row15_col2, #T_367ca_row15_col3, #T_367ca_row15_col4, #T_367ca_row15_col5, #T_367ca_row15_col6, #T_367ca_row16_col0, #T_367ca_row16_col1, #T_367ca_row16_col2, #T_367ca_row16_col3, #T_367ca_row16_col4, #T_367ca_row16_col5, #T_367ca_row16_col6, #T_367ca_row17_col0, #T_367ca_row17_col1, #T_367ca_row17_col2, #T_367ca_row17_col3, #T_367ca_row17_col4, #T_367ca_row17_col5, #T_367ca_row17_col6, #T_367ca_row18_col0, #T_367ca_row18_col1, #T_367ca_row18_col2, #T_367ca_row18_col3, #T_367ca_row18_col4, #T_367ca_row18_col5, #T_367ca_row18_col6 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_367ca_row0_col1, #T_367ca_row0_col2, #T_367ca_row0_col3, #T_367ca_row0_col4, #T_367ca_row0_col5, #T_367ca_row1_col6 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_367ca_row0_col7, #T_367ca_row1_col7, #T_367ca_row2_col7, #T_367ca_row3_col7, #T_367ca_row4_col7, #T_367ca_row5_col7, #T_367ca_row6_col7, #T_367ca_row7_col7, #T_367ca_row8_col7, #T_367ca_row9_col7, #T_367ca_row10_col7, #T_367ca_row12_col7, #T_367ca_row13_col7, #T_367ca_row14_col7, #T_367ca_row15_col7, #T_367ca_row17_col7 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_367ca_row11_col7, #T_367ca_row16_col7, #T_367ca_row18_col7 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_367ca\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_367ca_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_367ca_level0_col1\" class=\"col_heading level0 col1\" >MAE</th>\n",
       "      <th id=\"T_367ca_level0_col2\" class=\"col_heading level0 col2\" >MSE</th>\n",
       "      <th id=\"T_367ca_level0_col3\" class=\"col_heading level0 col3\" >RMSE</th>\n",
       "      <th id=\"T_367ca_level0_col4\" class=\"col_heading level0 col4\" >R2</th>\n",
       "      <th id=\"T_367ca_level0_col5\" class=\"col_heading level0 col5\" >RMSLE</th>\n",
       "      <th id=\"T_367ca_level0_col6\" class=\"col_heading level0 col6\" >MAPE</th>\n",
       "      <th id=\"T_367ca_level0_col7\" class=\"col_heading level0 col7\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_367ca_level0_row0\" class=\"row_heading level0 row0\" >et</th>\n",
       "      <td id=\"T_367ca_row0_col0\" class=\"data row0 col0\" >Extra Trees Regressor</td>\n",
       "      <td id=\"T_367ca_row0_col1\" class=\"data row0 col1\" >208.7641</td>\n",
       "      <td id=\"T_367ca_row0_col2\" class=\"data row0 col2\" >647137.1975</td>\n",
       "      <td id=\"T_367ca_row0_col3\" class=\"data row0 col3\" >758.1749</td>\n",
       "      <td id=\"T_367ca_row0_col4\" class=\"data row0 col4\" >0.9359</td>\n",
       "      <td id=\"T_367ca_row0_col5\" class=\"data row0 col5\" >0.1709</td>\n",
       "      <td id=\"T_367ca_row0_col6\" class=\"data row0 col6\" >0.0573</td>\n",
       "      <td id=\"T_367ca_row0_col7\" class=\"data row0 col7\" >0.0600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_367ca_level0_row1\" class=\"row_heading level0 row1\" >xgboost</th>\n",
       "      <td id=\"T_367ca_row1_col0\" class=\"data row1 col0\" >Extreme Gradient Boosting</td>\n",
       "      <td id=\"T_367ca_row1_col1\" class=\"data row1 col1\" >216.1014</td>\n",
       "      <td id=\"T_367ca_row1_col2\" class=\"data row1 col2\" >783961.5051</td>\n",
       "      <td id=\"T_367ca_row1_col3\" class=\"data row1 col3\" >788.8588</td>\n",
       "      <td id=\"T_367ca_row1_col4\" class=\"data row1 col4\" >0.9253</td>\n",
       "      <td id=\"T_367ca_row1_col5\" class=\"data row1 col5\" >0.1802</td>\n",
       "      <td id=\"T_367ca_row1_col6\" class=\"data row1 col6\" >0.0569</td>\n",
       "      <td id=\"T_367ca_row1_col7\" class=\"data row1 col7\" >0.1360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_367ca_level0_row2\" class=\"row_heading level0 row2\" >rf</th>\n",
       "      <td id=\"T_367ca_row2_col0\" class=\"data row2 col0\" >Random Forest Regressor</td>\n",
       "      <td id=\"T_367ca_row2_col1\" class=\"data row2 col1\" >431.5277</td>\n",
       "      <td id=\"T_367ca_row2_col2\" class=\"data row2 col2\" >991186.8812</td>\n",
       "      <td id=\"T_367ca_row2_col3\" class=\"data row2 col3\" >925.8144</td>\n",
       "      <td id=\"T_367ca_row2_col4\" class=\"data row2 col4\" >0.8993</td>\n",
       "      <td id=\"T_367ca_row2_col5\" class=\"data row2 col5\" >0.2148</td>\n",
       "      <td id=\"T_367ca_row2_col6\" class=\"data row2 col6\" >0.1220</td>\n",
       "      <td id=\"T_367ca_row2_col7\" class=\"data row2 col7\" >0.0640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_367ca_level0_row3\" class=\"row_heading level0 row3\" >dt</th>\n",
       "      <td id=\"T_367ca_row3_col0\" class=\"data row3 col0\" >Decision Tree Regressor</td>\n",
       "      <td id=\"T_367ca_row3_col1\" class=\"data row3 col1\" >276.0589</td>\n",
       "      <td id=\"T_367ca_row3_col2\" class=\"data row3 col2\" >1287128.7043</td>\n",
       "      <td id=\"T_367ca_row3_col3\" class=\"data row3 col3\" >959.5767</td>\n",
       "      <td id=\"T_367ca_row3_col4\" class=\"data row3 col4\" >0.8624</td>\n",
       "      <td id=\"T_367ca_row3_col5\" class=\"data row3 col5\" >0.2074</td>\n",
       "      <td id=\"T_367ca_row3_col6\" class=\"data row3 col6\" >0.0769</td>\n",
       "      <td id=\"T_367ca_row3_col7\" class=\"data row3 col7\" >0.0240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_367ca_level0_row4\" class=\"row_heading level0 row4\" >gbr</th>\n",
       "      <td id=\"T_367ca_row4_col0\" class=\"data row4 col0\" >Gradient Boosting Regressor</td>\n",
       "      <td id=\"T_367ca_row4_col1\" class=\"data row4 col1\" >904.1564</td>\n",
       "      <td id=\"T_367ca_row4_col2\" class=\"data row4 col2\" >1728644.0587</td>\n",
       "      <td id=\"T_367ca_row4_col3\" class=\"data row4 col3\" >1295.9219</td>\n",
       "      <td id=\"T_367ca_row4_col4\" class=\"data row4 col4\" >0.8226</td>\n",
       "      <td id=\"T_367ca_row4_col5\" class=\"data row4 col5\" >0.3272</td>\n",
       "      <td id=\"T_367ca_row4_col6\" class=\"data row4 col6\" >0.2775</td>\n",
       "      <td id=\"T_367ca_row4_col7\" class=\"data row4 col7\" >0.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_367ca_level0_row5\" class=\"row_heading level0 row5\" >lightgbm</th>\n",
       "      <td id=\"T_367ca_row5_col0\" class=\"data row5 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_367ca_row5_col1\" class=\"data row5 col1\" >1038.7595</td>\n",
       "      <td id=\"T_367ca_row5_col2\" class=\"data row5 col2\" >2163910.8359</td>\n",
       "      <td id=\"T_367ca_row5_col3\" class=\"data row5 col3\" >1465.2258</td>\n",
       "      <td id=\"T_367ca_row5_col4\" class=\"data row5 col4\" >0.7767</td>\n",
       "      <td id=\"T_367ca_row5_col5\" class=\"data row5 col5\" >0.3601</td>\n",
       "      <td id=\"T_367ca_row5_col6\" class=\"data row5 col6\" >0.3170</td>\n",
       "      <td id=\"T_367ca_row5_col7\" class=\"data row5 col7\" >0.0260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_367ca_level0_row6\" class=\"row_heading level0 row6\" >knn</th>\n",
       "      <td id=\"T_367ca_row6_col0\" class=\"data row6 col0\" >K Neighbors Regressor</td>\n",
       "      <td id=\"T_367ca_row6_col1\" class=\"data row6 col1\" >1112.0560</td>\n",
       "      <td id=\"T_367ca_row6_col2\" class=\"data row6 col2\" >3097784.9471</td>\n",
       "      <td id=\"T_367ca_row6_col3\" class=\"data row6 col3\" >1742.5710</td>\n",
       "      <td id=\"T_367ca_row6_col4\" class=\"data row6 col4\" >0.6825</td>\n",
       "      <td id=\"T_367ca_row6_col5\" class=\"data row6 col5\" >0.3561</td>\n",
       "      <td id=\"T_367ca_row6_col6\" class=\"data row6 col6\" >0.2700</td>\n",
       "      <td id=\"T_367ca_row6_col7\" class=\"data row6 col7\" >0.0210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_367ca_level0_row7\" class=\"row_heading level0 row7\" >ada</th>\n",
       "      <td id=\"T_367ca_row7_col0\" class=\"data row7 col0\" >AdaBoost Regressor</td>\n",
       "      <td id=\"T_367ca_row7_col1\" class=\"data row7 col1\" >2148.6350</td>\n",
       "      <td id=\"T_367ca_row7_col2\" class=\"data row7 col2\" >5743909.3677</td>\n",
       "      <td id=\"T_367ca_row7_col3\" class=\"data row7 col3\" >2391.6538</td>\n",
       "      <td id=\"T_367ca_row7_col4\" class=\"data row7 col4\" >0.4000</td>\n",
       "      <td id=\"T_367ca_row7_col5\" class=\"data row7 col5\" >0.6240</td>\n",
       "      <td id=\"T_367ca_row7_col6\" class=\"data row7 col6\" >0.7572</td>\n",
       "      <td id=\"T_367ca_row7_col7\" class=\"data row7 col7\" >0.0250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_367ca_level0_row8\" class=\"row_heading level0 row8\" >br</th>\n",
       "      <td id=\"T_367ca_row8_col0\" class=\"data row8 col0\" >Bayesian Ridge</td>\n",
       "      <td id=\"T_367ca_row8_col1\" class=\"data row8 col1\" >2492.0137</td>\n",
       "      <td id=\"T_367ca_row8_col2\" class=\"data row8 col2\" >9126338.1632</td>\n",
       "      <td id=\"T_367ca_row8_col3\" class=\"data row8 col3\" >3008.4373</td>\n",
       "      <td id=\"T_367ca_row8_col4\" class=\"data row8 col4\" >0.0733</td>\n",
       "      <td id=\"T_367ca_row8_col5\" class=\"data row8 col5\" >0.6716</td>\n",
       "      <td id=\"T_367ca_row8_col6\" class=\"data row8 col6\" >0.7747</td>\n",
       "      <td id=\"T_367ca_row8_col7\" class=\"data row8 col7\" >0.0180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_367ca_level0_row9\" class=\"row_heading level0 row9\" >ridge</th>\n",
       "      <td id=\"T_367ca_row9_col0\" class=\"data row9 col0\" >Ridge Regression</td>\n",
       "      <td id=\"T_367ca_row9_col1\" class=\"data row9 col1\" >2490.0811</td>\n",
       "      <td id=\"T_367ca_row9_col2\" class=\"data row9 col2\" >9125944.4340</td>\n",
       "      <td id=\"T_367ca_row9_col3\" class=\"data row9 col3\" >3008.5821</td>\n",
       "      <td id=\"T_367ca_row9_col4\" class=\"data row9 col4\" >0.0726</td>\n",
       "      <td id=\"T_367ca_row9_col5\" class=\"data row9 col5\" >0.6703</td>\n",
       "      <td id=\"T_367ca_row9_col6\" class=\"data row9 col6\" >0.7712</td>\n",
       "      <td id=\"T_367ca_row9_col7\" class=\"data row9 col7\" >0.0180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_367ca_level0_row10\" class=\"row_heading level0 row10\" >lar</th>\n",
       "      <td id=\"T_367ca_row10_col0\" class=\"data row10 col0\" >Least Angle Regression</td>\n",
       "      <td id=\"T_367ca_row10_col1\" class=\"data row10 col1\" >2490.0183</td>\n",
       "      <td id=\"T_367ca_row10_col2\" class=\"data row10 col2\" >9126422.3780</td>\n",
       "      <td id=\"T_367ca_row10_col3\" class=\"data row10 col3\" >3008.6755</td>\n",
       "      <td id=\"T_367ca_row10_col4\" class=\"data row10 col4\" >0.0725</td>\n",
       "      <td id=\"T_367ca_row10_col5\" class=\"data row10 col5\" >0.6702</td>\n",
       "      <td id=\"T_367ca_row10_col6\" class=\"data row10 col6\" >0.7710</td>\n",
       "      <td id=\"T_367ca_row10_col7\" class=\"data row10 col7\" >0.0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_367ca_level0_row11\" class=\"row_heading level0 row11\" >llar</th>\n",
       "      <td id=\"T_367ca_row11_col0\" class=\"data row11 col0\" >Lasso Least Angle Regression</td>\n",
       "      <td id=\"T_367ca_row11_col1\" class=\"data row11 col1\" >2490.0660</td>\n",
       "      <td id=\"T_367ca_row11_col2\" class=\"data row11 col2\" >9126381.6048</td>\n",
       "      <td id=\"T_367ca_row11_col3\" class=\"data row11 col3\" >3008.6612</td>\n",
       "      <td id=\"T_367ca_row11_col4\" class=\"data row11 col4\" >0.0725</td>\n",
       "      <td id=\"T_367ca_row11_col5\" class=\"data row11 col5\" >0.6703</td>\n",
       "      <td id=\"T_367ca_row11_col6\" class=\"data row11 col6\" >0.7711</td>\n",
       "      <td id=\"T_367ca_row11_col7\" class=\"data row11 col7\" >0.0170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_367ca_level0_row12\" class=\"row_heading level0 row12\" >lr</th>\n",
       "      <td id=\"T_367ca_row12_col0\" class=\"data row12 col0\" >Linear Regression</td>\n",
       "      <td id=\"T_367ca_row12_col1\" class=\"data row12 col1\" >2490.0183</td>\n",
       "      <td id=\"T_367ca_row12_col2\" class=\"data row12 col2\" >9126422.3817</td>\n",
       "      <td id=\"T_367ca_row12_col3\" class=\"data row12 col3\" >3008.6755</td>\n",
       "      <td id=\"T_367ca_row12_col4\" class=\"data row12 col4\" >0.0725</td>\n",
       "      <td id=\"T_367ca_row12_col5\" class=\"data row12 col5\" >0.6702</td>\n",
       "      <td id=\"T_367ca_row12_col6\" class=\"data row12 col6\" >0.7710</td>\n",
       "      <td id=\"T_367ca_row12_col7\" class=\"data row12 col7\" >0.5880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_367ca_level0_row13\" class=\"row_heading level0 row13\" >lasso</th>\n",
       "      <td id=\"T_367ca_row13_col0\" class=\"data row13 col0\" >Lasso Regression</td>\n",
       "      <td id=\"T_367ca_row13_col1\" class=\"data row13 col1\" >2490.0660</td>\n",
       "      <td id=\"T_367ca_row13_col2\" class=\"data row13 col2\" >9126381.6337</td>\n",
       "      <td id=\"T_367ca_row13_col3\" class=\"data row13 col3\" >3008.6612</td>\n",
       "      <td id=\"T_367ca_row13_col4\" class=\"data row13 col4\" >0.0725</td>\n",
       "      <td id=\"T_367ca_row13_col5\" class=\"data row13 col5\" >0.6703</td>\n",
       "      <td id=\"T_367ca_row13_col6\" class=\"data row13 col6\" >0.7711</td>\n",
       "      <td id=\"T_367ca_row13_col7\" class=\"data row13 col7\" >0.2190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_367ca_level0_row14\" class=\"row_heading level0 row14\" >en</th>\n",
       "      <td id=\"T_367ca_row14_col0\" class=\"data row14 col0\" >Elastic Net</td>\n",
       "      <td id=\"T_367ca_row14_col1\" class=\"data row14 col1\" >2527.9706</td>\n",
       "      <td id=\"T_367ca_row14_col2\" class=\"data row14 col2\" >9205987.0500</td>\n",
       "      <td id=\"T_367ca_row14_col3\" class=\"data row14 col3\" >3019.6821</td>\n",
       "      <td id=\"T_367ca_row14_col4\" class=\"data row14 col4\" >0.0708</td>\n",
       "      <td id=\"T_367ca_row14_col5\" class=\"data row14 col5\" >0.6833</td>\n",
       "      <td id=\"T_367ca_row14_col6\" class=\"data row14 col6\" >0.8041</td>\n",
       "      <td id=\"T_367ca_row14_col7\" class=\"data row14 col7\" >0.0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_367ca_level0_row15\" class=\"row_heading level0 row15\" >huber</th>\n",
       "      <td id=\"T_367ca_row15_col0\" class=\"data row15 col0\" >Huber Regressor</td>\n",
       "      <td id=\"T_367ca_row15_col1\" class=\"data row15 col1\" >2389.5812</td>\n",
       "      <td id=\"T_367ca_row15_col2\" class=\"data row15 col2\" >9511295.6389</td>\n",
       "      <td id=\"T_367ca_row15_col3\" class=\"data row15 col3\" >3067.1592</td>\n",
       "      <td id=\"T_367ca_row15_col4\" class=\"data row15 col4\" >0.0394</td>\n",
       "      <td id=\"T_367ca_row15_col5\" class=\"data row15 col5\" >0.6461</td>\n",
       "      <td id=\"T_367ca_row15_col6\" class=\"data row15 col6\" >0.6535</td>\n",
       "      <td id=\"T_367ca_row15_col7\" class=\"data row15 col7\" >0.0180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_367ca_level0_row16\" class=\"row_heading level0 row16\" >omp</th>\n",
       "      <td id=\"T_367ca_row16_col0\" class=\"data row16 col0\" >Orthogonal Matching Pursuit</td>\n",
       "      <td id=\"T_367ca_row16_col1\" class=\"data row16 col1\" >2594.0369</td>\n",
       "      <td id=\"T_367ca_row16_col2\" class=\"data row16 col2\" >9847366.4414</td>\n",
       "      <td id=\"T_367ca_row16_col3\" class=\"data row16 col3\" >3122.8522</td>\n",
       "      <td id=\"T_367ca_row16_col4\" class=\"data row16 col4\" >0.0036</td>\n",
       "      <td id=\"T_367ca_row16_col5\" class=\"data row16 col5\" >0.7071</td>\n",
       "      <td id=\"T_367ca_row16_col6\" class=\"data row16 col6\" >0.8346</td>\n",
       "      <td id=\"T_367ca_row16_col7\" class=\"data row16 col7\" >0.0170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_367ca_level0_row17\" class=\"row_heading level0 row17\" >dummy</th>\n",
       "      <td id=\"T_367ca_row17_col0\" class=\"data row17 col0\" >Dummy Regressor</td>\n",
       "      <td id=\"T_367ca_row17_col1\" class=\"data row17 col1\" >2642.7200</td>\n",
       "      <td id=\"T_367ca_row17_col2\" class=\"data row17 col2\" >10171861.2824</td>\n",
       "      <td id=\"T_367ca_row17_col3\" class=\"data row17 col3\" >3170.3037</td>\n",
       "      <td id=\"T_367ca_row17_col4\" class=\"data row17 col4\" >-0.0192</td>\n",
       "      <td id=\"T_367ca_row17_col5\" class=\"data row17 col5\" >0.7253</td>\n",
       "      <td id=\"T_367ca_row17_col6\" class=\"data row17 col6\" >0.8767</td>\n",
       "      <td id=\"T_367ca_row17_col7\" class=\"data row17 col7\" >0.0250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_367ca_level0_row18\" class=\"row_heading level0 row18\" >par</th>\n",
       "      <td id=\"T_367ca_row18_col0\" class=\"data row18 col0\" >Passive Aggressive Regressor</td>\n",
       "      <td id=\"T_367ca_row18_col1\" class=\"data row18 col1\" >2332.6393</td>\n",
       "      <td id=\"T_367ca_row18_col2\" class=\"data row18 col2\" >10236625.3423</td>\n",
       "      <td id=\"T_367ca_row18_col3\" class=\"data row18 col3\" >3179.0830</td>\n",
       "      <td id=\"T_367ca_row18_col4\" class=\"data row18 col4\" >-0.0346</td>\n",
       "      <td id=\"T_367ca_row18_col5\" class=\"data row18 col5\" >0.6483</td>\n",
       "      <td id=\"T_367ca_row18_col6\" class=\"data row18 col6\" >0.5688</td>\n",
       "      <td id=\"T_367ca_row18_col7\" class=\"data row18 col7\" >0.0170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x181a19a36d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesRegressor(n_jobs=-1, random_state=123)\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "from pycaret.regression import *\n",
    "import pandas as pd\n",
    "data = pd.read_csv('pca_reduced.csv')\n",
    "\n",
    "regression_setup = setup(\n",
    "    data,\n",
    "    target='price',\n",
    "    normalize=True,\n",
    "    train_size=0.8,\n",
    "    session_id=123,\n",
    "    log_experiment=True,\n",
    "    experiment_name='your_experiment_name'\n",
    ")\n",
    "\n",
    "best_models = compare_models()\n",
    "\n",
    "print(best_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'location_encoder.joblib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m location_encoder \u001b[39m=\u001b[39m LabelEncoder()\n\u001b[0;32m     14\u001b[0m room_type_encoder \u001b[39m=\u001b[39m LabelEncoder()\n\u001b[1;32m---> 15\u001b[0m location_encoder \u001b[39m=\u001b[39m joblib\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39mlocation_encoder.joblib\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     16\u001b[0m room_type_encoder \u001b[39m=\u001b[39m joblib\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39mtype_encoder.joblib\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     18\u001b[0m \u001b[39m# User input\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jaida\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\numpy_pickle.py:650\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, mmap_mode)\u001b[0m\n\u001b[0;32m    648\u001b[0m         obj \u001b[39m=\u001b[39m _unpickle(fobj)\n\u001b[0;32m    649\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(filename, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m    651\u001b[0m         \u001b[39mwith\u001b[39;00m _read_fileobject(f, filename, mmap_mode) \u001b[39mas\u001b[39;00m fobj:\n\u001b[0;32m    652\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(fobj, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    653\u001b[0m                 \u001b[39m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[0;32m    654\u001b[0m                 \u001b[39m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[0;32m    655\u001b[0m                 \u001b[39m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'location_encoder.joblib'"
     ]
    }
   ],
   "source": [
    "#user prediction\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from pycaret.regression import load_model, predict_model\n",
    "\n",
    "# Load the label encoders\n",
    "location_encoder = LabelEncoder()\n",
    "room_type_encoder = LabelEncoder()\n",
    "location_encoder = joblib.load('location_encoder.joblib')\n",
    "room_type_encoder = joblib.load('type_encoder.joblib')\n",
    "\n",
    "# User input\n",
    "user_location = input(\"Enter the location: \").strip().lower()\n",
    "user_room_type = input(\"Enter the room type: \").strip().lower()\n",
    "user_amenities = input(\"Enter the amenities: \").strip()\n",
    "\n",
    "# Encode user inputs\n",
    "encoded_location = location_encoder.transform([user_location])[0]\n",
    "encoded_room_type = room_type_encoder.transform([user_room_type])[0]\n",
    "\n",
    "\n",
    "# Preprocess amenities text\n",
    "def custom_tokenizer(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    pos_tags = pos_tag(tokens)  # Perform POS tagging\n",
    "    filtered_tokens = [token for token, pos in pos_tags if pos not in ['RB', 'JJ', 'VB']]  # Filter out adverbs, adjectives, and verbs\n",
    "    return filtered_tokens\n",
    "\n",
    "# Apply the same preprocessing to user amenities\n",
    "user_amenities_tfidf = vectorizer.transform([user_amenities])\n",
    "user_amenities_df = pd.DataFrame(user_amenities_tfidf.toarray(), columns=vectorizer.get_feature_names())\n",
    "\n",
    "# Create a dataframe with the user inputs\n",
    "user_input_df = pd.DataFrame({\n",
    "    'location': [encoded_location],\n",
    "    'type': [encoded_room_type]\n",
    "})\n",
    "user_processed = user_input_df.copy()\n",
    "user_processed.columns = [re.sub('[^A-Za-z]+', '', col) for col in user_processed.columns]\n",
    "user_processed = pd.concat([user_processed, amenities_df.iloc[:1]], axis=1)\n",
    "#user_processed.drop(columns=['amenities', 'distance'], axis=1, inplace=True)\n",
    "user_scaled = scaler.transform(user_processed)\n",
    "user_pca = pca.transform(user_scaled)\n",
    "user_pca_df = pd.DataFrame(data=user_pca, columns=['PC1', 'PC2'])\n",
    "predictions = predict_model(best_models, data=user_pca_df)\n",
    "predicted_price = predictions['prediction_label'].iloc[0]\n",
    "print(f\"Predicted price for the given input: {predicted_price}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'combined_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m combined_df\n",
      "\u001b[1;31mNameError\u001b[0m: name 'combined_df' is not defined"
     ]
    }
   ],
   "source": [
    "combined_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
